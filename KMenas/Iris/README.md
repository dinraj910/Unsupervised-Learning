# K-Means Clustering on Iris Dataset

## ğŸ“– Introduction

This project demonstrates **K-Means clustering**, an **unsupervised learning algorithm**, applied on the famous **Iris dataset**.  
If you're a beginner, donâ€™t worry! This README will explain **everything step by step** so that by the end, youâ€™ll **master K-Means** and understand how clustering works.

---

## ğŸŒ¸ What is the Iris Dataset?

The Iris dataset is a famous dataset in machine learning, introduced by the statistician **Ronald Fisher** in 1936.  
It contains measurements of **150 iris flowers** belonging to **3 species**:

- **Setosa**
- **Versicolor**
- **Virginica**

Each flower has **4 features**:

1. Sepal length (cm)  
2. Sepal width (cm)  
3. Petal length (cm)  
4. Petal width (cm)

Our goal: **Group these flowers into clusters using K-Means** â€” without looking at the species labels.

---

## ğŸ¤” What is K-Means Clustering?

K-Means is an **unsupervised machine learning algorithm** used for **clustering data**.

### ğŸ”‘ Key Definitions

- **Clustering** â†’ Grouping similar data points together.  
- **Centroid** â†’ The "center" of a cluster.  
- **K (Number of clusters)** â†’ The number of groups we want to divide the data into.  
- **Iterations** â†’ The repeated process of assigning points to clusters and updating centroids until the algorithm stabilizes.

### âš™ï¸ How K-Means Works

1. **Choose K** (number of clusters).  
2. **Randomly place K centroids**.  
3. **Assign each data point** to the nearest centroid.  
4. **Recalculate centroids** based on assigned points.  
5. **Repeat** steps 3â€“4 until centroids donâ€™t change much.

This way, similar data points end up in the same cluster.

---

## ğŸ§‘â€ğŸ’» Steps in Our Code

### 1. Import Libraries
We import `pandas`, `numpy`, `matplotlib`, and `sklearn` libraries.

### 2. Load Dataset
We load the **Iris dataset** from `sklearn.datasets`.

### 3. Visualize Data
We check the distribution of features and species.

### 4. Apply K-Means
We use `KMeans(n_clusters=3)` to cluster the data into **3 groups** (since we know there are 3 species).

### 5. Evaluation
- We compare predicted clusters with actual labels.  
- We use **confusion matrix** and **accuracy** to check performance.

### 6. Visualization
We plot clusters to visually see how K-Means separated the flowers.

---

## ğŸ“Š Output

### Example Cluster Plot
Below is the visualization of how K-Means clustered the flowers:

![alt text](image.png)

![alt text](image-1.png)

---

## ğŸ“ˆ Evaluation Metrics

- **Confusion Matrix** â†’ Compares actual species vs predicted clusters.  
- **Accuracy** â†’ Percentage of correctly clustered flowers.

> Note: K-Means is unsupervised, so accuracy is just for reference (clusters may not align exactly with labels).

---

## ğŸ” Insights from the Project

## ğŸ’¡ Insights from K-Means on Iris

**Unsupervised grouping works well**

Even though K-Means didnâ€™t know the real species labels (Setosa, Versicolor, Virginica), it could separate the flowers into groups just based on feature patterns (sepal length, sepal width, petal length, petal width).

**Cluster quality depends on K**

Using the Elbow Method, we saw the curve flatten at K=3â€“4, meaning that 3 clusters capture the natural structure of data without over-complicating.

Using the Silhouette Score, we saw the best separation at K=2, but thatâ€™s because Iris species 2 & 3 (Versicolor & Virginica) are quite similar, and the algorithm sometimes merges them.

**Interpretation with ground truth**

Real labels = 3 species.

K-Means clustering with K=3 roughly matches these species:

- Cluster 0 â‰ˆ Setosa (well-separated, almost perfect).
- Cluster 1 â‰ˆ Versicolor.
- Cluster 2 â‰ˆ Virginica.

But Versicolor & Virginica overlap, so sometimes misclassifications happen.

**Practical takeaway**

K-Means found structure without labels â€” this is the essence of unsupervised learning.

It shows us how features group naturally, and helps us evaluate if labels (species) align with actual feature distributions.

âœ… **Final Insight:**
By applying K-Means, we discovered that the Iris dataset naturally forms 2â€“3 meaningful groups:

1 clear group (Setosa).
2 overlapping groups (Versicolor & Virginica).

---

## ğŸ§  Why is This Important?

- K-Means is widely used in **customer segmentation**, **market analysis**, **image compression**, and more.  
- This project gives you hands-on experience with an **unsupervised ML algorithm**.  
- After this, youâ€™ll be confident in applying clustering to other datasets.

---

## ğŸš€ Next Steps for You

1. Try the **Elbow Method** to find the best K.  
2. Apply K-Means on **different datasets** (customers, images, etc.).  
3. Explore other clustering algorithms like **DBSCAN** or **Hierarchical Clustering**.

---

## âœ… Conclusion

- We applied **K-Means clustering** to the Iris dataset.  
- Learned how clustering works step by step.  
- Visualized clusters and understood insights.  

ğŸ‘‰ By reading this README and running the code, even a beginner can **master K-Means**! ğŸ‰

---

## ğŸ“‚ Project Structure

```
KMeans_iris.ipynb    # Jupyter Notebook with code
README.md            # Documentation (this file)
cluster_plot.png     # Output visualization
```

---

## ğŸ™Œ Author

**Your Name**  
Mastering ML, one project at a time ğŸš€
